{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0hMNE02o2FI+icvsJ1n1b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mridul-sahu/jax-sharding-tutorials/blob/main/Chapter_1_2_Single_Host_Sharding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Series 1, Chapter 1.2: Single-Host Sharding with `jax.pmap` - Foundations of Data Parallelism] - The Aurora Project ðŸŒŒ\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome back, Aurora Architect! In our previous briefing (Chapter 1.1), we established a deep understanding of JAX data primitivesâ€”`Array`s, host versus device memory, and the art of explicit data placement using `jax.device_put` and `jax.device_get`. We learned to command individual data elements with precision.\n",
        "\n",
        "However, Project Aurora's ambitions require us to process datasets and train models far too large for any single accelerator core. We must harness the combined power of multiple devices working in concert. Our first major step into this parallel universe is **`jax.pmap`** (parallel map). This transformation is a cornerstone for single-host, multi-device parallelism, allowing us to replicate a computation across multiple local devices (like GPUs or TPU cores on a single machine) and process different chunks of data simultaneouslyâ€”the essence of **data parallelism**.\n",
        "\n",
        "**Chapter Goal:** This chapter will equip you to use `jax.pmap` to distribute computations and data across all available devices on a single Aurora node. You will learn to control how data is split (scattered) to devices and how results are combined (gathered), and to perform essential inter-device communication using JAX collectives.\n",
        "\n",
        "**Topic Introduction:** We'll delve into the mechanics of `jax.pmap`, including function replication and the critical `in_axes` and `out_axes` arguments for controlling data mapping. We will explore how to prepare data for parallel processing, perform collective operations like `psum` for aggregating results (e.g., gradients), and understand the memory implications and limitations of this powerful, yet foundational, parallelism strategy.\n",
        "\n",
        "**Outcome Statement:** By the end of this chapter, you will be proficient in implementing basic data parallelism using `jax.pmap`, enabling significant speedups for many of Aurora's training tasks on multi-accelerator single hosts. You'll also understand its operational model, laying the groundwork for more advanced sharding techniques to come.\n",
        "\n",
        "### Learning Objectives for This Phase:\n",
        "\n",
        "* Implement data parallelism on multiple devices on a single host using `jax.pmap`.\n",
        "* Master the usage of `in_axes` and `out_axes` to control data distribution and collection.\n",
        "* Utilize `jax.lax` collectives (e.g., `psum`, `pmean`) within `pmap` for inter-device communication.\n",
        "* Analyze memory usage patterns and limitations of the `pmap` model.\n",
        "\n",
        "### Chapter Outline:\n",
        "\n",
        "1.  **The Essence of `pmap`: Function Replication & \"SPMD Lite\"**\n",
        "2.  **Preparing Data for Parallel Execution: Physical Splitting** (`numpy.split`)\n",
        "3.  **Mapping Data to Devices: The `in_axes` Argument**\n",
        "4.  **Consolidating Results: The `out_axes` Argument**\n",
        "5.  **Handling Constants Efficiently: `static_broadcast_argnums`**\n",
        "6.  **Targeting Specific Devices with `pmap`'s `devices` Argument**\n",
        "7.  **Inter-Device Alchemy: Collectives within `pmap`** (`jax.lax.psum`, `pmean`, `all_gather`)\n",
        "8.  **The Memory Footprint of `pmap`: Considerations for Aurora**\n",
        "9.  **`pmap` in Practice: Use Cases, Strengths, and Limitations**\n",
        "\n",
        "## Core Concepts Refresher\n",
        "\n",
        "Before diving into `pmap`, let's recall from Chapter 1.1:\n",
        "* **JAX Arrays & Device Affinity:** JAX arrays (`DeviceArray`s) reside on specific devices.\n",
        "* **Explicit Placement:** We can use `jax.device_put` for precise control, though `pmap` will also manage placement.\n",
        "* **Asynchronous Dispatch:** JAX operations, especially on accelerators, are often asynchronous. `block_until_ready()` is key for synchronization when needed.\n",
        "\n",
        "`pmap` builds upon these concepts by taking a function and running it concurrently across multiple devices, each operating on its designated piece of data. It's a form of SPMD (Single Program, Multiple Data) programming, though JAX handles much of the complexity.\n",
        "\n",
        "\n",
        "First, let's set up our JAX environment and check available devices. The effectiveness of `pmap` shines when multiple devices are present."
      ],
      "metadata": {
        "id": "3FNKYKgDoFiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLjkj98ToENx",
        "outputId": "83a37efa-652d-432e-e981-ce84960452d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX version: 0.5.2\n",
            "JAX default backend: cpu\n",
            "Number of local JAX devices available: 4\n",
            "Available devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Forcing 4 CPU devices for pmap demonstration on CPU runtime.\n",
        "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=4'\n",
        "\n",
        "print(f\"JAX version: {jax.__version__}\")\n",
        "print(f\"JAX default backend: {jax.default_backend()}\")\n",
        "\n",
        "# After potential restart (if on CPU and setting XLA_FLAGS), re-initialize JAX context implicitly by using JAX\n",
        "num_devices = jax.local_device_count()\n",
        "devices = jax.local_devices()\n",
        "\n",
        "print(f\"Number of local JAX devices available: {num_devices}\")\n",
        "print(f\"Available devices: {devices}\")\n",
        "\n",
        "# Ensure we have at least one device to proceed\n",
        "if num_devices == 0:\n",
        "    raise RuntimeError(\"No JAX devices found. pmap requires at least one device.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. The Essence of `pmap`: Function Replication & \"SPMD Lite\"\n",
        "\n",
        "`jax.pmap` (parallel map) is a JAX transformation that takes a function and compiles it to run in parallel on multiple XLA devices (e.g., GPUs, TPU cores).\n",
        "\n",
        "**Core Mechanics:**\n",
        "* **Function Replication:** The function you pass to `pmap` is replicated across all specified devices (or all available local devices by default). Each device executes the *same* function.\n",
        "* **Data Parallelism (SPMD style):** While the program (function) is the same, each replica typically operates on a different *slice* of the input data. This is the essence of Single Program, Multiple Data (SPMD).\n",
        "* **Input/Output Handling:** `pmap` needs to know how the input data should be distributed (sharded/split) across devices and how the outputs from each device should be combined or returned. This is primarily controlled by the `in_axes` and `out_axes` arguments.\n",
        "\n",
        "Think of it as an advanced version of Python's `map`, but supercharged for parallel execution on hardware accelerators."
      ],
      "metadata": {
        "id": "dD8R-5rvsnNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple function we want to run in parallel\n",
        "def scale(x_shard, scale_factor_on_device):\n",
        "  return (x_shard) * scale_factor_on_device\n",
        "\n",
        "# Prepare data: ensure the leading dimension matches num_devices for sharding.\n",
        "# Each device will get one row from 'sharded_x' and one element from 'sharded_scale_factors'.\n",
        "example_elements_per_device = 4\n",
        "sharded_x_data = jnp.arange(num_devices * example_elements_per_device, dtype=jnp.float32).reshape(num_devices, example_elements_per_device)\n",
        "\n",
        "# Example: different scale factor for each device to demonstrate sharded arguments.\n",
        "sharded_scale_factors_data = jnp.array([10.0 * (i + 1) for i in range(num_devices)], dtype=jnp.float32)\n",
        "\n",
        "# pmap the function\n",
        "# in_axes=(0, 0) means:\n",
        "# - For 'x_shard' (first arg): its 0-th axis is the device axis (sharded).\n",
        "# - For 'scale_factor_on_device' (second arg): its 0-th axis is the device axis (sharded).\n",
        "# axis_name='i' names the mapped axis, used by collectives like jax.lax.axis_index.\n",
        "pmapped_scaled_square_fn = jax.pmap(scale, in_axes=(0, 0), axis_name='i')\n",
        "\n",
        "# Run the pmapped function\n",
        "result_from_pmap = pmapped_scaled_square_fn(sharded_x_data, sharded_scale_factors_data)\n",
        "\n",
        "print(f\"\\nInput sharded_x_data:\\n{sharded_x_data}\")\n",
        "print(f\"Input sharded_scale_factors_data:\\n{sharded_scale_factors_data}\")\n",
        "print(f\"Pmap result (output from all devices stacked):\\n{result_from_pmap}\")\n",
        "print(f\"Result shape: {result_from_pmap.shape} (Should be: num_devices, elements_per_device)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJrktJ2jqo7y",
        "outputId": "dbfd7104-d33f-464e-e48f-f511b4b843ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input sharded_x_data:\n",
            "[[ 0.  1.  2.  3.]\n",
            " [ 4.  5.  6.  7.]\n",
            " [ 8.  9. 10. 11.]\n",
            " [12. 13. 14. 15.]]\n",
            "Input sharded_scale_factors_data:\n",
            "[10. 20. 30. 40.]\n",
            "Pmap result (output from all devices stacked):\n",
            "[[  0.  10.  20.  30.]\n",
            " [ 80. 100. 120. 140.]\n",
            " [240. 270. 300. 330.]\n",
            " [480. 520. 560. 600.]]\n",
            "Result shape: (4, 4) (Should be: num_devices, elements_per_device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Preparing Data for Parallel Execution: Physical Splitting (`numpy.split`)\n",
        "\n",
        "For `pmap` to distribute data effectively using `in_axes` (covered next), the input arrays typically need a leading dimension that matches the number of devices we are `pmap`ping over. Each slice along this leading dimension goes to one device.\n",
        "\n",
        "A common way to prepare data is to use `numpy.split` (or `jnp.split`) if your data isn't already in this shape."
      ],
      "metadata": {
        "id": "1235mteawiJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global data for Aurora's simulations (e.g., a batch of inputs)\n",
        "# Ensure batch_size is a multiple of num_devices for easy splitting.\n",
        "total_batch_size = 8 * num_devices\n",
        "feature_size = 3\n",
        "global_aurora_data = np.random.rand(total_batch_size, feature_size).astype(np.float32)\n",
        "print(f\"Global Aurora data shape: {global_aurora_data.shape}\")\n",
        "\n",
        "# We need to split the data into num_devices chunks along the batch axis (axis 0).\n",
        "# Each chunk will be processed by one device.\n",
        "sharded_data_list_np = np.split(global_aurora_data, num_devices, axis=0)\n",
        "\n",
        "# sharded_data_list_np is a list of NumPy arrays.\n",
        "# For pmap, we typically stack them back into a single NumPy array\n",
        "# where the first dimension is the device dimension.\n",
        "prepared_data_for_pmap_stacked = np.stack(sharded_data_list_np, axis=0)\n",
        "\n",
        "# Alternatively, if global_data's first dimension is already divisible by num_devices,\n",
        "# we can often just reshape it directly.\n",
        "per_device_batch_size = total_batch_size // num_devices\n",
        "prepared_data_for_pmap_reshaped = global_aurora_data.reshape(num_devices, per_device_batch_size, feature_size)\n",
        "\n",
        "print(f\"\\nShape after np.stack(np.split(...)): {prepared_data_for_pmap_stacked.shape}\")\n",
        "print(f\"Shape after direct reshape: {prepared_data_for_pmap_reshaped.shape}\")\n",
        "assert prepared_data_for_pmap_stacked.shape == prepared_data_for_pmap_reshaped.shape\n",
        "# Both shapes should be: (num_devices, per_device_batch_size, feature_size)\n",
        "\n",
        "# For subsequent examples, we'll use the reshaped version.\n",
        "current_prepared_data = prepared_data_for_pmap_reshaped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uim2yenjygcR",
        "outputId": "1bc058a6-a8d8-4839-bf9c-e77331f92ccc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Aurora data shape: (32, 3)\n",
            "\n",
            "Shape after np.stack(np.split(...)): (4, 8, 3)\n",
            "Shape after direct reshape: (4, 8, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `current_prepared_data` now has a leading axis that `pmap` can map to devices.\n",
        "\n",
        "### 3. Mapping Data to Devices: The `in_axes` Argument\n",
        "\n",
        "The `in_axes` argument of `pmap` is crucial. It tells `pmap` how to distribute the input arguments of the mapped function across the devices.\n",
        "* `in_axes` is a tuple/list specifying, for each positional argument of the function, which axis of that argument should be mapped to the devices.\n",
        "* An integer `d` means the `d`-th axis of the corresponding input array is the \"device axis.\" Data along this axis is split and distributed.\n",
        "* `None` means the corresponding input argument is *replicated* (broadcasted) to all devices. This is for data that should be identical for all parallel executions."
      ],
      "metadata": {
        "id": "OwwAaVzXy0TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_shard_example(data_shard, replicated_scalar_param):\n",
        "  # data_shard is the piece of data specific to this device.\n",
        "  # replicated_scalar_param is the same for all devices.\n",
        "  return jnp.sum(data_shard * replicated_scalar_param, axis=0) # Example: sum features per device\n",
        "\n",
        "# Our current_prepared_data has shape (num_devices, per_device_batch_size, feature_size)\n",
        "# We want to map axis 0 of current_prepared_data to devices.\n",
        "# The replicated_scalar_param should be the same for all devices.\n",
        "aurora_scalar_param = jnp.array(5.0, dtype=jnp.float32) # A scalar JAX array\n",
        "\n",
        "# pmap the function\n",
        "# in_axes=(0, None) means:\n",
        "# - For 'data_shard' (first arg): map its 0-th axis to devices.\n",
        "# - For 'replicated_scalar_param' (second arg): replicate it to all devices.\n",
        "pmapped_process_fn = jax.pmap(process_data_shard_example,\n",
        "                              in_axes=(0, None),\n",
        "                              axis_name='data_axis')\n",
        "\n",
        "# Run the pmapped function\n",
        "result_in_axes_example = pmapped_process_fn(current_prepared_data, aurora_scalar_param)\n",
        "\n",
        "print(f\"\\n--- pmap with in_axes=(0, None) ---\")\n",
        "print(f\"Input data shape for pmap: {current_prepared_data.shape}\")\n",
        "print(f\"Replicated param: {aurora_scalar_param}\")\n",
        "print(f\"Result from pmap (raw): \\n{result_in_axes_example}\")\n",
        "print(f\"Result shape: {result_in_axes_example.shape}\")\n",
        "# The result will have a leading dimension equal to num_devices,\n",
        "# each element being the output from one device.\n",
        "# Shape: (num_devices, feature_size) because we summed over per_device_batch_size."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2WBy-vWzTUF",
        "outputId": "09b71e50-45e5-4f8f-94a3-5e3dc1dd4ccc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- pmap with in_axes=(0, None) ---\n",
            "Input data shape for pmap: (4, 8, 3)\n",
            "Replicated param: 5.0\n",
            "Result from pmap (raw): \n",
            "[[23.570044 17.356874 21.184027]\n",
            " [18.736385 23.411463 19.134218]\n",
            " [18.431837 19.805702 25.691887]\n",
            " [17.981094 19.538786 15.820544]]\n",
            "Result shape: (4, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, `current_prepared_data` (shape `(N, B, F)`) is passed. `in_axes=(0, None)` means:\n",
        "* The first argument (`data_shard`) receives slices from `current_prepared_data` along its 0-th axis. So, device `i` gets `current_prepared_data[i]`, which has shape `(B, F)`.\n",
        "* The second argument (`replicated_scalar_param`) receives the `aurora_scalar_param` value replicated on all devices.\n",
        "\n",
        "### 4. Consolidating Results: The `out_axes` Argument\n",
        "\n",
        "Just as `in_axes` controls input distribution, `out_axes` controls how results from each device are combined (or kept separate) in the final output array.\n",
        "* If `out_axes` is `d` (an integer), the outputs from each device (which are expected to be arrays) are stacked along a new axis `d` in the output. The default for `out_axes` is `0`.\n",
        "* If `out_axes` is `None`, the output from each device must be identical, and `pmap` returns just one copy of this identical output. This is useful if all devices are expected to compute the exact same final scalar after some collective, for example."
      ],
      "metadata": {
        "id": "YXvFsHNfzacF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Understanding out_axes ---\")\n",
        "print(f\"Previous pmap result (default out_axes=0): \\n{result_in_axes_example}\")\n",
        "print(f\"Shape (default out_axes=0): {result_in_axes_example.shape}\") # (num_devices, feature_size)\n",
        "\n",
        "# Example: What if the function returned a scalar from each device,\n",
        "# and we still want them stacked (default out_axes=0)?\n",
        "def process_to_scalar_sum_example(data_shard, replicated_param):\n",
        "    return jnp.sum(data_shard * replicated_param) # Returns a scalar\n",
        "\n",
        "pmapped_scalar_output_fn = jax.pmap(process_to_scalar_sum_example, in_axes=(0, None)) # out_axes defaults to 0\n",
        "scalar_results_stacked = pmapped_scalar_output_fn(current_prepared_data, aurora_scalar_param) # uses data from previous cell\n",
        "print(f\"\\nScalar results from each device (stacked by default out_axes=0):\\n{scalar_results_stacked}\")\n",
        "print(f\"Shape: {scalar_results_stacked.shape}\") # (num_devices,)\n",
        "\n",
        "# Example: If out_axes=None, all devices must return the same value.\n",
        "# This is usually used when a collective operation (like psum over all results)\n",
        "# already produces an identical result on all devices.\n",
        "def process_and_return_fixed_value(data_shard_ignored, param_ignored):\n",
        "    # For out_axes=None to be valid, the values returned by each device MUST be identical.\n",
        "    # This function simulates that by returning a constant.\n",
        "    # A more realistic scenario involves a collective (see later section).\n",
        "    return jnp.array(42.0)\n",
        "\n",
        "# All inputs are effectively ignored or could be None if the function doesn't use them.\n",
        "# For pmap to trace correctly and know the number of devices,\n",
        "# it usually infers from sharded inputs. If all in_axes are None,\n",
        "# pmap applies to all jax.local_devices().\n",
        "# We provide a dummy sharded input to make the number of devices explicit for pmap.\n",
        "dummy_sharded_input_for_out_axes_none = jnp.zeros((num_devices, 1))\n",
        "\n",
        "pmapped_identical_output_fn = jax.pmap(process_and_return_fixed_value,\n",
        "                                      in_axes=(0, None), # Dummy sharded, dummy replicated\n",
        "                                      out_axes=None) # Key part for this example\n",
        "\n",
        "identical_result = pmapped_identical_output_fn(dummy_sharded_input_for_out_axes_none, None)\n",
        "print(f\"\\nIdentical result (out_axes=None):\\n{identical_result}\")\n",
        "print(f\"Shape: {identical_result.shape}\") # Scalar, no device dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6PgZrcRz9hu",
        "outputId": "e1a8e571-6280-4e20-c4d8-432a7ef14725"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Understanding out_axes ---\n",
            "Previous pmap result (default out_axes=0): \n",
            "[[23.570044 17.356874 21.184027]\n",
            " [18.736385 23.411463 19.134218]\n",
            " [18.431837 19.805702 25.691887]\n",
            " [17.981094 19.538786 15.820544]]\n",
            "Shape (default out_axes=0): (4, 3)\n",
            "\n",
            "Scalar results from each device (stacked by default out_axes=0):\n",
            "[62.110943 61.282063 63.929436 53.340424]\n",
            "Shape: (4,)\n",
            "\n",
            "Identical result (out_axes=None):\n",
            "42.0\n",
            "Shape: ()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, `out_axes=0` is the most common behavior, giving you an array where the 0-th axis represents the devices.\n",
        "\n",
        "### 5. Handling Constants Efficiently: `static_broadcasted_argnums`\n",
        "\n",
        "Sometimes, arguments to your `pmap`ped function are Python scalars/strings or JAX arrays that should be treated as compile-time constants and broadcasted efficiently, rather than being processed as per-device data or runtime replicated JAX arrays. This is where `static_broadcasted_argnums` comes in.\n",
        "\n",
        "* Arguments listed in `static_broadcasted_argnums` are \"baked into\" the compiled function for each device.\n",
        "* They must be hashable and define `__eq__` (standard Python types like int, str, bool, or JAX arrays that are compile-time constants).\n",
        "* This avoids unnecessary device transfers or replication of data that is truly static.\n",
        "* If an argument is static, it is NOT included in `in_axes` corresponding to its position. `in_axes` entries are for non-static arguments."
      ],
      "metadata": {
        "id": "DkneXbxh0Nl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_static_op_example(x_dynamic_shard, static_python_val: int, another_dynamic_val_replicated):\n",
        "  # static_python_val will be a compile-time constant here.\n",
        "  # JAX traces the function for each unique value of static_python_val.\n",
        "  print(f\"my_static_op_example TRACED/RUN with static_python_val = {static_python_val}\")\n",
        "  if static_python_val > 5:\n",
        "    return x_dynamic_shard * 100 + another_dynamic_val_replicated\n",
        "  else:\n",
        "    return x_dynamic_shard * static_python_val + another_dynamic_val_replicated\n",
        "\n",
        "# static_python_val (arg index 1) will be static.\n",
        "# `in_axes` should only specify axes for dynamic arguments.\n",
        "# arg0 (x_dynamic_shard) is sharded -> in_axes[0] = 0\n",
        "# arg2 (another_dynamic_val_replicated) is replicated -> in_axes[1] = None\n",
        "pmapped_static_op_fn = jax.pmap(my_static_op_example,\n",
        "                              static_broadcasted_argnums=(1,), # Index of 'static_python_val'\n",
        "                              in_axes=(0, None, None)\n",
        "                            )\n",
        "\n",
        "# Take a slice for simplicity, e.g., first feature from each device's batch.\n",
        "# Shape: (num_devices, per_device_batch_size)\n",
        "dynamic_input_shards = current_prepared_data[:, :, 0]\n",
        "another_dynamic_param_replicated = jnp.array(0.5, dtype=jnp.float32) # Replicated via in_axes=None\n",
        "\n",
        "print(f\"\\n--- pmap with static_broadcast_argnums ---\")\n",
        "# Call with static_python_val = 7\n",
        "# JAX will compile a version of my_static_op_example specialized for static_python_val=7.\n",
        "print(\"Calling with static_val=7 (expect compilation if first time with this value)...\")\n",
        "result_static_7 = pmapped_static_op_fn(dynamic_input_shards, 7, another_dynamic_param_replicated)\n",
        "print(f\"Result with static_val=7 (first element from each device):\\n{result_static_7[:, 0]}\")\n",
        "\n",
        "# Call with static_python_val = 3\n",
        "# This will trigger a re-compilation because 'static_python_val' changed,\n",
        "# unless a version for 3 was already compiled and cached.\n",
        "print(\"\\nCalling with a different static_val (static_val=3), expect a JAX compilation message (if not cached)...\")\n",
        "result_static_3 = pmapped_static_op_fn(dynamic_input_shards, 3, another_dynamic_param_replicated)\n",
        "print(f\"Result with static_val=3 (first element from each device):\\n{result_static_3[:, 0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEkontTx1Pdx",
        "outputId": "48477ece-2ec8-4010-d74d-ce83f6b63406"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- pmap with static_broadcast_argnums ---\n",
            "Calling with static_val=7 (expect compilation if first time with this value)...\n",
            "my_static_op_example TRACED/RUN with static_python_val = 7\n",
            "Result with static_val=7 (first element from each device):\n",
            "[65.99184  89.81062  68.202095 53.22373 ]\n",
            "\n",
            "Calling with a different static_val (static_val=3), expect a JAX compilation message (if not cached)...\n",
            "my_static_op_example TRACED/RUN with static_python_val = 3\n",
            "Result with static_val=3 (first element from each device):\n",
            "[2.464755  3.1793187 2.5310628 2.0817118]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pro-Tip:** Using `static_broadcasted_argnums` is crucial for arguments that control the structure of the computation (e.g., boolean flags, dimensions used in reshapes inside the function). Changing a static argument forces recompilation if that specific version isn't cached.\n",
        "\n",
        "### 6. Targeting Specific Devices with `pmap`'s `devices` Argument\n",
        "\n",
        "By default, `pmap` uses all `jax.local_devices()`. However, you can explicitly specify a list of devices for `pmap` to use. This is useful for more complex scenarios, like manually assigning parts of a model to specific subsets of devices on a host (though `jax.sharding` APIs are generally preferred for more advanced device management today)."
      ],
      "metadata": {
        "id": "FEGWFpqt1Sc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the first half of available devices, or just the first device if only 1 would result.\n",
        "num_subset_devices = max(1, num_devices // 2)\n",
        "subset_target_devices = devices[:num_subset_devices]\n",
        "\n",
        "print(f\"\\n--- pmap with explicit 'devices' argument ---\")\n",
        "print(f\"All available devices: {devices}\")\n",
        "print(f\"Targeting subset of devices for pmap: {subset_target_devices}\")\n",
        "\n",
        "# Prepare data specifically for this subset of devices.\n",
        "# Ensure total_batch_size_for_subset is a multiple of num_subset_devices.\n",
        "per_device_batch_for_subset = current_prepared_data.shape[1] # Use same per-device batch as before\n",
        "total_batch_size_for_subset = num_subset_devices * per_device_batch_for_subset\n",
        "\n",
        "# For simplicity, we'll reshape a slice of the previously prepared data.\n",
        "subset_global_data_slice = global_aurora_data[:total_batch_size_for_subset, :]\n",
        "\n",
        "subset_prepared_data = subset_global_data_slice.reshape(num_subset_devices, per_device_batch_for_subset, feature_size)\n",
        "\n",
        "pmapped_on_subset_fn = jax.pmap(process_data_shard_example, # Using the function from in_axes example\n",
        "                              in_axes=(0, None), # data sharded, param replicated\n",
        "                              devices=subset_target_devices,\n",
        "                              axis_name='data_axis_subset')\n",
        "\n",
        "result_on_subset = pmapped_on_subset_fn(subset_prepared_data, aurora_scalar_param)\n",
        "print(f\"Input data shape for subset pmap: {subset_prepared_data.shape}\")\n",
        "print(f\"Result from pmap on subset of devices:\\n{result_on_subset}\")\n",
        "print(f\"Result shape: {result_on_subset.shape}\") # Leading dim will be num_subset_devices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6meiPIk3Bma",
        "outputId": "406839b9-9be7-49ac-9d64-e6f7531b3576"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- pmap with explicit 'devices' argument ---\n",
            "All available devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
            "Targeting subset of devices for pmap: [CpuDevice(id=0), CpuDevice(id=1)]\n",
            "Input data shape for subset pmap: (2, 8, 3)\n",
            "Result from pmap on subset of devices:\n",
            "[[23.570044 17.356874 21.184027]\n",
            " [18.736385 23.411463 19.134218]]\n",
            "Result shape: (2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Inter-Device Alchemy: Collectives within `pmap`\n",
        "\n",
        "When each device processes its data shard, we often need to combine or share information *between* these parallel executions. This is where **collective operations** come in. `jax.lax` provides several collectives that work seamlessly inside `pmap`.\n",
        "\n",
        "Inside a `pmap`ped function:\n",
        "* An \"axis name\" is implicitly defined by `pmap` (internally often named 'i', but you can specify one using `axis_name` argument in `pmap`). You refer to this axis in collectives.\n",
        "* **`jax.lax.psum(x, axis_name)`**: Computes the sum of `x` across all devices participating in the `pmap` along the named axis. The result is broadcast back to all devices, so each device receives the same total sum.\n",
        "* **`jax.lax.pmean(x, axis_name)`**: Computes the mean of `x` across all devices. Result is broadcast.\n",
        "* **`jax.lax.all_gather(x, axis_name, tiled=False)`**: Gathers the value of `x` from all devices and concatenates them along a new leading axis (if `x` is a vector/matrix) or creates a vector (if `x` is scalar). The result is broadcast. If `tiled=True`, it's used when `x` is a slice of a larger array that was split across devices, and `all_gather` reconstructs the full array."
      ],
      "metadata": {
        "id": "bEbEeCXf3M0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the axis name for pmap collectives, matching pmap's axis_name argument.\n",
        "PMAP_COLLECTIVES_AXIS_NAME = 'aurora_data_parallel_mesh'\n",
        "\n",
        "def process_with_collectives_example(data_shard_input, model_weights_replicated):\n",
        "    # 1. Per-device computation (e.g., local \"predictions\" or \"gradients\")\n",
        "    # data_shard_input shape: (per_device_batch_size, in_features)\n",
        "    # model_weights_replicated shape: (in_features, out_features)\n",
        "    local_output = jnp.dot(data_shard_input, model_weights_replicated) # Shape: (per_device_batch_size, out_features)\n",
        "\n",
        "    # 2. Sum outputs across all devices using psum.\n",
        "    # Each device will receive the same 'global_sum_output'.\n",
        "    global_sum_output = jax.lax.psum(local_output, axis_name=PMAP_COLLECTIVES_AXIS_NAME)\n",
        "\n",
        "    # 3. Calculate the mean of a specific value (e.g., first element of the first batch item's output) across devices.\n",
        "    mean_of_specific_value = jax.lax.pmean(local_output[0,0], axis_name=PMAP_COLLECTIVES_AXIS_NAME)\n",
        "\n",
        "    # 4. Gather all 'local_output' first rows from all devices using all_gather.\n",
        "    # Each device's local_output[0,:] is a vector of shape (out_features,).\n",
        "    # all_gather will stack these vectors, resulting in an array of shape (num_devices, out_features) on each device.\n",
        "    gathered_first_rows_from_all_devices = jax.lax.all_gather(local_output[0,:], axis_name=PMAP_COLLECTIVES_AXIS_NAME)\n",
        "    # If tiled=True, all_gather(local_output, ...) would try to reconstruct a global tensor assuming local_output is a tile.\n",
        "\n",
        "    return global_sum_output, mean_of_specific_value, gathered_first_rows_from_all_devices\n",
        "\n",
        "\n",
        "# Dummy model weights for the example\n",
        "in_features = current_prepared_data.shape[2] # feature_size\n",
        "out_feature_size_example = 2\n",
        "# These weights will be replicated to all devices via in_axes=None.\n",
        "aurora_model_weights = jnp.array(np.random.rand(in_features, out_feature_size_example).astype(np.float32))\n",
        "\n",
        "pmapped_collective_op_fn = jax.pmap(process_with_collectives_example,\n",
        "                                  in_axes=(0, None), # data sharded, weights replicated\n",
        "                                  axis_name=PMAP_COLLECTIVES_AXIS_NAME) # Crucial for collectives\n",
        "\n",
        "# Run the pmapped function\n",
        "# current_prepared_data shape: (num_devices, per_device_batch_size, in_features)\n",
        "summed_res, mean_res, gathered_res = pmapped_collective_op_fn(current_prepared_data, aurora_model_weights)\n",
        "\n",
        "print(f\"\\n--- pmap with Collectives (axis_name='{PMAP_COLLECTIVES_AXIS_NAME}') ---\")\n",
        "print(f\"Model weights (replicated) shape: {aurora_model_weights.shape}\")\n",
        "\n",
        "# --- Analyzing psum result ---\n",
        "# `summed_res` itself will be sharded by pmap's default out_axes=0.\n",
        "# So, summed_res has shape (num_devices, per_device_batch_size, out_feature_size_example).\n",
        "# The key is that summed_res[0], summed_res[1], etc., are ALL IDENTICAL, containing the global sum.\n",
        "print(f\"\\nGlobal Summed Result (via psum):\")\n",
        "print(f\"  Shape of 'summed_res' (outer device dim from pmap): {summed_res.shape}\")\n",
        "# Verify all devices have the same sum by comparing the slice from device 0 with device 1 (if available).\n",
        "print(f\"  summed_res[0] and summed_res[1] are identical: {np.allclose(summed_res[0], summed_res[1])}\")\n",
        "print(f\"  Example value from one device (actual global sum, e.g., first batch item):\\n{summed_res[0,0,:]}\")\n",
        "\n",
        "# --- Analyzing pmean result ---\n",
        "# `mean_res` will have shape (num_devices,) because pmap's default out_axes=0 stacks the scalar mean from each device.\n",
        "# Again, mean_res[0], mean_res[1], etc., are all identical.\n",
        "print(f\"\\nGlobal Mean of Specific Value (via pmean):\")\n",
        "print(f\"  Shape of 'mean_res': {mean_res.shape}\") # (num_devices,)\n",
        "print(f\"  Value on first device (actual global mean): {mean_res[0]}\")\n",
        "print(f\"  mean_res[0] and mean_res[1] are identical: {np.allclose(mean_res[0], mean_res[1])}\")\n",
        "\n",
        "# --- Analyzing all_gather result ---\n",
        "# `gathered_res` will have shape (num_devices, num_devices_again, out_feature_size_example).\n",
        "# The outer num_devices is from pmap's default out_axes=0.\n",
        "# The inner num_devices_again is because all_gather(vector_from_each_device) produces a matrix of shape (num_devices, out_feature_size_example) on EACH device.\n",
        "# So, gathered_res[i] contains this (num_devices, out_feature_size_example) matrix as seen by device i.\n",
        "# And gathered_res[i,j,:] is the local_output[0,:] from original device j.\n",
        "print(f\"\\nGathered First Rows (via all_gather):\")\n",
        "print(f\"  Shape of 'gathered_res': {gathered_res.shape}\")\n",
        "print(f\"  Example value (all gathered rows as seen by device 0):\\n{gathered_res[0]}\")\n",
        "print(f\"  gathered_res[0] and gathered_res[1] are identical: {np.allclose(gathered_res[0], gathered_res[1])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVAjZhTd3Tg-",
        "outputId": "243cd6b8-72b9-4de3-b30f-7ab591f289ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- pmap with Collectives (axis_name='aurora_data_parallel_mesh') ---\n",
            "Model weights (replicated) shape: (3, 2)\n",
            "\n",
            "Global Summed Result (via psum):\n",
            "  Shape of 'summed_res' (outer device dim from pmap): (4, 8, 2)\n",
            "  summed_res[0] and summed_res[1] are identical: True\n",
            "  Example value from one device (actual global sum, e.g., first batch item):\n",
            "[3.1516733 2.5336175]\n",
            "\n",
            "Global Mean of Specific Value (via pmean):\n",
            "  Shape of 'mean_res': (4,)\n",
            "  Value on first device (actual global mean): 0.7879183292388916\n",
            "  mean_res[0] and mean_res[1] are identical: True\n",
            "\n",
            "Gathered First Rows (via all_gather):\n",
            "  Shape of 'gathered_res': (4, 4, 2)\n",
            "  Example value (all gathered rows as seen by device 0):\n",
            "[[0.6746523  0.5609971 ]\n",
            " [0.699285   0.61584073]\n",
            " [1.0759616  0.7655081 ]\n",
            " [0.7017747  0.5912713 ]]\n",
            "  gathered_res[0] and gathered_res[1] are identical: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collectives are the backbone of distributed training, allowing gradients to be summed, metrics to be averaged, or parameters to be synchronized across all parallel workers.\n",
        "\n",
        "### 8. The Memory Footprint of `pmap`: Considerations for Aurora\n",
        "\n",
        "While `pmap` enables parallelism, it's crucial to understand its memory implications for Project Aurora:\n",
        "* **Data Replication (for `in_axes=None`):** Arguments with `in_axes=None` are replicated. If these are large arrays (e.g., model parameters in simple data parallelism), a full copy resides on *each* device. This can severely limit model size.\n",
        "* **Per-Device Data Shards:** The sharded data still consumes memory on each device.\n",
        "* **Intermediate Activations:** Each device computes its own intermediate activations during the forward/backward pass. These also consume memory per device.\n",
        "* **Function Code:** The compiled function code is replicated on each device, usually a smaller concern.\n",
        "* **Output Buffers:** Buffers for outputs are allocated on each device.\n",
        "\n",
        "If your model parameters are too large to fit on a single device alongside activations and data shards, simple `pmap` data parallelism (where parameters are replicated) won't work. This limitation is a key motivator for more advanced sharding strategies (model parallelism, Fully Sharded Data Parallel - FSDP) that we'll explore later in Project Aurora.\n",
        "\n",
        "### 9. `pmap` in Practice: Use Cases, Strengths, and Limitations\n",
        "\n",
        "**Ideal Use Cases & Strengths for Aurora:**\n",
        "* **Data Parallel Training (Small to Medium Models):** When model parameters and optimizer states fit comfortably on each device, `pmap` is excellent for distributing the data batch and speeding up training.\n",
        "* **Parallel Inference/Evaluation:** Evaluating a model on large batches of data by splitting the batch across devices.\n",
        "* **Simple Embarrassingly Parallel Tasks:** Any task where you can split work into independent chunks (e.g., running multiple simulations with different initial seeds, if seeds are part of sharded input).\n",
        "* **Ease of Use:** For basic data parallelism, `pmap` is relatively straightforward to implement compared to more manual sharding approaches.\n",
        "\n",
        "**Shortcomings & Limitations:**\n",
        "* **Single Host Only:** `pmap` is designed for devices connected to a single host machine. It doesn't inherently scale across multiple nodes in a cluster (that's for `jax.distributed` and global meshes, covered later).\n",
        "* **Memory Constraints (Replicated Parameters):** As mentioned, replicating large model parameters across all devices is a major bottleneck for very large models.\n",
        "* **Limited Parallelism Types:** `pmap` is primarily for data parallelism. Implementing complex model parallelism or pipeline parallelism with `pmap` alone is cumbersome and often inefficient.\n",
        "* **Collectives Scope:** Collectives operate over all devices `pmap` is running on. Finer-grained control over communication subgroups is not directly supported by `pmap` (requiring `shard_map` or custom mesh setups explored in later chapters).\n",
        "\n",
        "For Project Aurora, `pmap` is a vital initial tool for leveraging multi-accelerator nodes. However, to build truly colossal models, we will need to transcend its limitations with the more advanced sharding APIs introduced in subsequent chapters.\n",
        "\n",
        "## Chapter Debrief: `pmap` Milestones Achieved!\n",
        "\n",
        "**Summary:**\n",
        "Excellent work, Architect! You've successfully unlocked single-host, multi-device parallelism for Project Aurora using `jax.pmap`. You've learned to replicate computations, strategically distribute data shards using `in_axes`, manage output aggregation with `out_axes`, and leverage powerful inter-device communication via collectives like `psum`, `pmean`, and `all_gather`. You also now appreciate the memory model of `pmap` and its ideal use cases and limitations.\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "* `jax.pmap` enables SPMD-style data parallelism by replicating a function across local devices.\n",
        "* `in_axes` dictates how input array axes are mapped to devices (sharded) or replicated.\n",
        "* `out_axes` controls how results from devices are combined or returned. `static_broadcasted_argnums` handles compile-time constants efficiently.\n",
        "* `jax.lax` collectives (`psum`, `pmean`, `all_gather`) are essential for inter-device communication within `pmap`, using a specified `axis_name`.\n",
        "* `pmap` is powerful for data parallelism when models fit in single-device memory, but parameter replication limits its use for extremely large models. Data must typically be pre-sharded with a leading device axis.\n",
        "\n",
        "**Transition:**\n",
        "While `pmap` significantly boosts our processing power on a single Aurora node, its view of devices is somewhat \"flat\"â€”a simple list. For more sophisticated parallelism strategies, especially when coordinating many devices in potentially multi-dimensional topologies (even on a single host initially), we need a more structured way to view and address our hardware. This leads us to **Chapter 1.3: Global Device `Mesh` - Abstracting Hardware Topology for Advanced Sharding**, where we'll learn to define logical meshes that map to our physical devices, paving the way for the modern `jax.sharding` API.\n",
        "\n",
        "## Further Reading & Resources\n",
        "\n",
        "* **JAX API Documentation - `jax.pmap`**: [https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap](https://jax.readthedocs.io/en/latest/jax.html#parallelization-pmap)\n",
        "* **JAX Lax Parallel Operators**: [https://jax.readthedocs.io/en/latest/jax.lax.html#parallel-operators](https://jax.readthedocs.io/en/latest/jax.lax.html#parallel-operators)"
      ],
      "metadata": {
        "id": "TKTK3Wk54gvb"
      }
    }
  ]
}